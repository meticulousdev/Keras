{"cells":[{"cell_type":"code","execution_count":1,"source":["import string\n","\n","class Vectorizer:\n","    def standardize(self, text):\n","        text = text.lower()\n","        return \"\".join(char for char in text if char not in string.punctuation)\n","\n","    def tokenize(self, text):\n","        return text.split()\n","\n","    def make_vocabulary(self, dataset):\n","        self.vocabulary = {\"\": 0, \"[UNK]\": 1}\n","        for text in dataset:\n","            text = self.standardize(text)\n","            tokens = self.tokenize(text)\n","            for token in tokens:\n","                if token not in self.vocabulary:\n","                    self.vocabulary[token] = len(self.vocabulary)\n","        self.inverse_vocabulary = dict((v, k) for k, v in self.vocabulary.items())\n","\n","    def encode(self, text):\n","        text = self.standardize(text)\n","        tokens = self.tokenize(text)\n","        return [self.vocabulary.get(token, 1) for token in tokens]\n","\n","    def decode(self, int_sequence):\n","        return \" \".join(\n","            self.inverse_vocabulary.get(i, \"[UNK]\") for i in int_sequence)"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":2,"source":["vectorizer = Vectorizer()\n","dataset = [\"I write, erase, rewrite\",\n","           \"Erase again, and then\",\n","           \"A poppy blooms.\",]\n","vectorizer.make_vocabulary(dataset)"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":3,"source":["vectorizer.inverse_vocabulary"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["{0: '',\n"," 1: '[UNK]',\n"," 2: 'i',\n"," 3: 'write',\n"," 4: 'erase',\n"," 5: 'rewrite',\n"," 6: 'again',\n"," 7: 'and',\n"," 8: 'then',\n"," 9: 'a',\n"," 10: 'poppy',\n"," 11: 'blooms'}"]},"metadata":{},"execution_count":3}],"metadata":{}}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":3},"orig_nbformat":4}}