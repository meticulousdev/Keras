{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "%cd /content/drive/MyDrive/Colab\\ Notebooks/Keras/code_2nd/chap11"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99aH0WkNyQZw",
        "outputId": "6dbeff2b-8a2a-4c24-c2ac-a84d4aef3a1e"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/Colab Notebooks/Keras/code_2nd/chap11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JHC5wgjxPHWH",
        "outputId": "68bc87a3-1402-4e7d-dfa7-cb9baa548c1d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 80.2M  100 80.2M    0     0  8048k      0  0:00:10  0:00:10 --:--:-- 15.6M\n"
          ]
        }
      ],
      "source": [
        "# !curl -O https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
        "# !tar -xf aclImdb_v1.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "irDrd9GJPHWH"
      },
      "outputs": [],
      "source": [
        "# !rm -r aclImdb/train/unsup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pPt42d2WPHWH",
        "outputId": "ed64527c-ab47-4ed6-bec4-4506ce172714",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I first saw this back in the early 90s on UK TV, i did like it then but i missed the chance to tape it, many years passed but the film always stuck with me and i lost hope of seeing it TV again, the main thing that stuck with me was the end, the hole castle part really touched me, its easy to watch, has a great story, great music, the list goes on and on, its OK me saying how good it is but everyone will take there own best bits away with them once they have seen it, yes the animation is top notch and beautiful to watch, it does show its age in a very few parts but that has now become part of it beauty, i am so glad it has came out on DVD as it is one of my top 10 films of all time. Buy it or rent it just see it, best viewing is at night alone with drink and food in reach so you don't have to stop the film.<br /><br />Enjoy"
          ]
        }
      ],
      "source": [
        "# !cat aclImdb/train/pos/4077_10.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VqMxuzj8PHWI"
      },
      "outputs": [],
      "source": [
        "import os, pathlib, shutil, random\n",
        "\n",
        "base_dir = pathlib.Path(\"aclImdb\")\n",
        "val_dir = base_dir / \"val\"\n",
        "train_dir = base_dir / \"train\"\n",
        "for category in (\"neg\", \"pos\"):\n",
        "    os.makedirs(val_dir / category)\n",
        "    files = os.listdir(train_dir / category)\n",
        "    random.Random(1337).shuffle(files)\n",
        "    num_val_samples = int(0.2 * len(files))\n",
        "    val_files = files[-num_val_samples:]\n",
        "    for fname in val_files:\n",
        "        shutil.move(train_dir / category / fname,\n",
        "                    val_dir / category / fname)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nCA9IoOKPHWI",
        "outputId": "036ee296-201e-4e64-f175-67b0fbc13d58",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 20000 files belonging to 2 classes.\n",
            "Found 5000 files belonging to 2 classes.\n",
            "Found 25000 files belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "from tensorflow import keras\n",
        "batch_size = 32\n",
        "\n",
        "train_ds = keras.utils.text_dataset_from_directory(\n",
        "    \"aclImdb/train\", batch_size=batch_size\n",
        ")\n",
        "val_ds = keras.utils.text_dataset_from_directory(\n",
        "    \"aclImdb/val\", batch_size=batch_size\n",
        ")\n",
        "test_ds = keras.utils.text_dataset_from_directory(\n",
        "    \"aclImdb/test\", batch_size=batch_size\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RO58kApSPHWI",
        "outputId": "720b9ef5-8460-49fe-ebaf-64b0147553de",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs.shape: (32,)\n",
            "inputs.dtype: <dtype: 'string'>\n",
            "targets.shape: (32,)\n",
            "targets.dtype: <dtype: 'int32'>\n",
            "inputs[0]: tf.Tensor(b'Meek, tiny, almost insignificant. Polanski finds the invisibility of his characters and makes something enormous out of it. In front and behind the camera he creates one of the most uncomfortable masterpieces I had the pleasure to see and see and see again. It never let\\'s me down. People, even people who know me pretty well, thought/think there was/is something wrong with me, based on my attraction, or I should say, devotion for \"Le Locataire\" They may be right, I don\\'t know but there is something irresistibly enthralling within Polanski\\'s darkness and I haven\\'t even mentioned the humor. The mystery surrounding the apartment and the previous tenant, the mystery that takes over him and, naturally, us, me. That building populated by great old Academy Award winners: Melvyn Douglas, Shelley Winters, Jo Van Fleet, Lila Kedrova. For anyone who loves movies, this is compulsory viewing. One, two, three, many, many viewings.', shape=(), dtype=string)\n",
            "targets[0]: tf.Tensor(1, shape=(), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "for inputs, targets in train_ds:\n",
        "    print(\"inputs.shape:\", inputs.shape)\n",
        "    print(\"inputs.dtype:\", inputs.dtype)\n",
        "    print(\"targets.shape:\", targets.shape)\n",
        "    print(\"targets.dtype:\", targets.dtype)\n",
        "    print(\"inputs[0]:\", inputs[0])\n",
        "    print(\"targets[0]:\", targets[0])\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import TextVectorization\n",
        "text_vectorization = TextVectorization(output_mode=\"int\",)"
      ],
      "metadata": {
        "id": "OJXpDC-h2Ozc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import string\n",
        "import tensorflow as tf\n",
        "\n",
        "def custom_standardization_fn(string_tensor):\n",
        "    lowercase_string = tf.strings.lower(string_tensor)\n",
        "    return tf.strings.regex_replace(\n",
        "        lowercase_string, f\"[{re.escape(string.punctuation)}]\", \"\")\n",
        "\n",
        "def custom_split_fn(string_tensor):\n",
        "    return tf.strings.split(string_tensor)\n",
        "\n",
        "text_vectorization = TextVectorization(\n",
        "    output_mode=\"int\",\n",
        "    standardize=custom_standardization_fn,\n",
        "    split=custom_split_fn,\n",
        ")"
      ],
      "metadata": {
        "id": "Bl6XUdJO2Qtz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eOSiAiGPPHWJ"
      },
      "outputs": [],
      "source": [
        "text_vectorization = TextVectorization(\n",
        "    max_tokens=20000,\n",
        "    output_mode=\"multi_hot\",\n",
        ")\n",
        "text_only_train_ds = train_ds.map(lambda x, y: x)\n",
        "text_vectorization.adapt(text_only_train_ds)\n",
        "\n",
        "binary_1gram_train_ds = train_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),\n",
        "    num_parallel_calls=4)\n",
        "binary_1gram_val_ds = val_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),\n",
        "    num_parallel_calls=4)\n",
        "binary_1gram_test_ds = test_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),\n",
        "    num_parallel_calls=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aKTPekqmPHWJ",
        "outputId": "7c91e758-fb2a-4980-c780-c97915ee6a40",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs.shape: (32, 20000)\n",
            "inputs.dtype: <dtype: 'float32'>\n",
            "targets.shape: (32,)\n",
            "targets.dtype: <dtype: 'int32'>\n",
            "inputs[0]: tf.Tensor([1. 1. 1. ... 0. 0. 0.], shape=(20000,), dtype=float32)\n",
            "targets[0]: tf.Tensor(1, shape=(), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "for inputs, targets in binary_1gram_train_ds:\n",
        "    print(\"inputs.shape:\", inputs.shape)\n",
        "    print(\"inputs.dtype:\", inputs.dtype)\n",
        "    print(\"targets.shape:\", targets.shape)\n",
        "    print(\"targets.dtype:\", targets.dtype)\n",
        "    print(\"inputs[0]:\", inputs[0])\n",
        "    print(\"targets[0]:\", targets[0])\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ODGXYjUcPHWK"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "def get_model(max_tokens=20000, hidden_dim=16):\n",
        "    inputs = keras.Input(shape=(max_tokens,))\n",
        "    x = layers.Dense(hidden_dim, activation=\"relu\")(inputs)\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "    outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "    model = keras.Model(inputs, outputs)\n",
        "    model.compile(optimizer=\"rmsprop\",\n",
        "                  loss=\"binary_crossentropy\",\n",
        "                  metrics=[\"accuracy\"])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fmb0uHkyPHWK",
        "outputId": "d774d330-ca06-49db-fe50-266646048318",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 20000)]           0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 16)                320016    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 16)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 320,033\n",
            "Trainable params: 320,033\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "625/625 [==============================] - 26s 37ms/step - loss: 0.4431 - accuracy: 0.8110 - val_loss: 0.3332 - val_accuracy: 0.8736\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.3045 - accuracy: 0.8893 - val_loss: 0.3141 - val_accuracy: 0.8834\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.2730 - accuracy: 0.9056 - val_loss: 0.3268 - val_accuracy: 0.8802\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 2s 4ms/step - loss: 0.2563 - accuracy: 0.9108 - val_loss: 0.3281 - val_accuracy: 0.8832\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.2494 - accuracy: 0.9136 - val_loss: 0.3410 - val_accuracy: 0.8802\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 2s 4ms/step - loss: 0.2416 - accuracy: 0.9151 - val_loss: 0.3542 - val_accuracy: 0.8788\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.2368 - accuracy: 0.9191 - val_loss: 0.3793 - val_accuracy: 0.8760\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 2s 4ms/step - loss: 0.2412 - accuracy: 0.9168 - val_loss: 0.3847 - val_accuracy: 0.8792\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.2400 - accuracy: 0.9201 - val_loss: 0.3858 - val_accuracy: 0.8772\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 2s 4ms/step - loss: 0.2316 - accuracy: 0.9240 - val_loss: 0.3870 - val_accuracy: 0.8770\n",
            "782/782 [==============================] - 23s 29ms/step - loss: 0.3161 - accuracy: 0.8793\n",
            "테스트 정확도: 0.879\n"
          ]
        }
      ],
      "source": [
        "model = get_model()\n",
        "model.summary()\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\"binary_1gram.keras\",\n",
        "                                    save_best_only=True)\n",
        "]\n",
        "model.fit(binary_1gram_train_ds.cache(),\n",
        "          validation_data=binary_1gram_val_ds.cache(),\n",
        "          epochs=10,\n",
        "          callbacks=callbacks)\n",
        "model = keras.models.load_model(\"binary_1gram.keras\")\n",
        "print(f\"테스트 정확도: {model.evaluate(binary_1gram_test_ds)[1]:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O_xsjJvdPHWK"
      },
      "outputs": [],
      "source": [
        "text_vectorization = TextVectorization(\n",
        "    ngrams=2,\n",
        "    max_tokens=20000,\n",
        "    output_mode=\"multi_hot\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7hJTKCooPHWL",
        "outputId": "c6687146-08fa-4a2c-e8a3-999048f167e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 20000)]           0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 16)                320016    \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 16)                0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 320,033\n",
            "Trainable params: 320,033\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "625/625 [==============================] - 25s 39ms/step - loss: 0.3850 - accuracy: 0.8395 - val_loss: 0.2713 - val_accuracy: 0.8944\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 2s 4ms/step - loss: 0.2459 - accuracy: 0.9129 - val_loss: 0.2762 - val_accuracy: 0.8954\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.2126 - accuracy: 0.9313 - val_loss: 0.2889 - val_accuracy: 0.8984\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.1977 - accuracy: 0.9401 - val_loss: 0.3047 - val_accuracy: 0.8982\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.1908 - accuracy: 0.9427 - val_loss: 0.3145 - val_accuracy: 0.9014\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.1795 - accuracy: 0.9496 - val_loss: 0.3433 - val_accuracy: 0.8964\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 2s 4ms/step - loss: 0.1784 - accuracy: 0.9507 - val_loss: 0.3487 - val_accuracy: 0.8986\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.1683 - accuracy: 0.9529 - val_loss: 0.3575 - val_accuracy: 0.8978\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 2s 4ms/step - loss: 0.1804 - accuracy: 0.9537 - val_loss: 0.3591 - val_accuracy: 0.8982\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.1741 - accuracy: 0.9553 - val_loss: 0.3635 - val_accuracy: 0.8960\n",
            "782/782 [==============================] - 26s 33ms/step - loss: 0.2720 - accuracy: 0.8980\n",
            "테스트 정확도: 0.898\n"
          ]
        }
      ],
      "source": [
        "text_vectorization.adapt(text_only_train_ds)\n",
        "binary_2gram_train_ds = train_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),\n",
        "    num_parallel_calls=4)\n",
        "binary_2gram_val_ds = val_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),\n",
        "    num_parallel_calls=4)\n",
        "binary_2gram_test_ds = test_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),\n",
        "    num_parallel_calls=4)\n",
        "\n",
        "model = get_model()\n",
        "model.summary()\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\"binary_2gram.keras\",\n",
        "                                    save_best_only=True)\n",
        "]\n",
        "model.fit(binary_2gram_train_ds.cache(),\n",
        "          validation_data=binary_2gram_val_ds.cache(),\n",
        "          epochs=10,\n",
        "          callbacks=callbacks)\n",
        "model = keras.models.load_model(\"binary_2gram.keras\")\n",
        "print(f\"테스트 정확도: {model.evaluate(binary_2gram_test_ds)[1]:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TAHAvzsgPHWL"
      },
      "outputs": [],
      "source": [
        "text_vectorization = TextVectorization(\n",
        "    ngrams=2,\n",
        "    max_tokens=20000,\n",
        "    output_mode=\"count\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Um9A6ydPHWL"
      },
      "outputs": [],
      "source": [
        "text_vectorization = TextVectorization(\n",
        "    ngrams=2,\n",
        "    max_tokens=20000,\n",
        "    output_mode=\"tf_idf\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AGhSasurPHWM",
        "outputId": "c589d6a2-6774-4b4d-d659-276c306a14a7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 20000)]           0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 16)                320016    \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 16)                0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 320,033\n",
            "Trainable params: 320,033\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "625/625 [==============================] - 24s 38ms/step - loss: 0.5201 - accuracy: 0.7812 - val_loss: 0.2879 - val_accuracy: 0.8906\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.3252 - accuracy: 0.8659 - val_loss: 0.2796 - val_accuracy: 0.8980\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.2846 - accuracy: 0.8839 - val_loss: 0.3069 - val_accuracy: 0.8928\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.2652 - accuracy: 0.8900 - val_loss: 0.3165 - val_accuracy: 0.8950\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.2459 - accuracy: 0.8987 - val_loss: 0.3297 - val_accuracy: 0.8898\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.2385 - accuracy: 0.8998 - val_loss: 0.3326 - val_accuracy: 0.8902\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.2223 - accuracy: 0.9058 - val_loss: 0.3320 - val_accuracy: 0.8896\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.2223 - accuracy: 0.9103 - val_loss: 0.3344 - val_accuracy: 0.8942\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.2138 - accuracy: 0.9104 - val_loss: 0.3796 - val_accuracy: 0.8856\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.2097 - accuracy: 0.9121 - val_loss: 0.3596 - val_accuracy: 0.8846\n",
            "782/782 [==============================] - 23s 29ms/step - loss: 0.2862 - accuracy: 0.8900\n",
            "테스트 정확도: 0.890\n"
          ]
        }
      ],
      "source": [
        "with tf.device(\"cpu\"):\n",
        "    text_vectorization.adapt(text_only_train_ds)\n",
        "\n",
        "tfidf_2gram_train_ds = train_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),\n",
        "    num_parallel_calls=4)\n",
        "tfidf_2gram_val_ds = val_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),\n",
        "    num_parallel_calls=4)\n",
        "tfidf_2gram_test_ds = test_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),\n",
        "    num_parallel_calls=4)\n",
        "\n",
        "model = get_model()\n",
        "model.summary()\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\"tfidf_2gram.keras\",\n",
        "                                    save_best_only=True)\n",
        "]\n",
        "model.fit(tfidf_2gram_train_ds.cache(),\n",
        "          validation_data=tfidf_2gram_val_ds.cache(),\n",
        "          epochs=10,\n",
        "          callbacks=callbacks)\n",
        "model = keras.models.load_model(\"tfidf_2gram.keras\")\n",
        "print(f\"테스트 정확도: {model.evaluate(tfidf_2gram_test_ds)[1]:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tGIbe1KrPHWM"
      },
      "outputs": [],
      "source": [
        "inputs = keras.Input(shape=(1,), dtype=\"string\")\n",
        "processed_inputs = text_vectorization(inputs)\n",
        "outputs = model(processed_inputs)\n",
        "inference_model = keras.Model(inputs, outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XBEraM_0PHWM",
        "outputId": "22d97887-58bf-4aa7-eae5-0bed9bbc280a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "긍정적인 리뷰일 확률: 97.26 퍼센트\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "raw_text_data = tf.convert_to_tensor([\n",
        "    [\"That was an excellent movie, I loved it.\"],\n",
        "])\n",
        "predictions = inference_model(raw_text_data)\n",
        "print(f\"긍정적인 리뷰일 확률: {float(predictions[0] * 100):.2f} 퍼센트\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}