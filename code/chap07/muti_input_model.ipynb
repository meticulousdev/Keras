{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Input\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vocabulary_size = 10000\n",
    "question_vocabulary_size = 10000\n",
    "answer_vocabulary_size = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-06 01:25:14.062877: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-07-06 01:25:14.063040: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "text_input = Input(shape=(None,), dtype='int32', name='text')\n",
    "embedded_text = layers.Embedding(64, text_vocabulary_size)(text_input)\n",
    "encoded_text = layers.LSTM(32)(embedded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_input = Input(shape=(None,), dtype='int32', name='question')\n",
    "embedded_question = layers.Embedding(32, question_vocabulary_size)(question_input)\n",
    "encoded_question = layers.LSTM(16)(embedded_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate axis=-1 (?)\n",
    "concatenated = layers.concatenate([encoded_text, encoded_question], axis=-1)\n",
    "answer = layers.Dense(answer_vocabulary_size,\n",
    "activation='softmax')(concatenated)\n",
    "model = Model([text_input, question_input], answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x : (2, 2, 5) \n",
      "[[[ 0  1  2  3  4]\n",
      "  [ 5  6  7  8  9]]\n",
      "\n",
      " [[10 11 12 13 14]\n",
      "  [15 16 17 18 19]]]\n",
      "y : (2, 1, 5) \n",
      "[[[20 21 22 23 24]]\n",
      "\n",
      " [[25 26 27 28 29]]]\n",
      "z : (2, 2, 5) \n",
      "[[[20 21 22 23 24]\n",
      "  [25 26 27 28 29]]\n",
      "\n",
      " [[30 31 32 33 34]\n",
      "  [35 36 37 38 39]]]\n",
      "xy (axis=1):\n",
      "tf.Tensor(\n",
      "[[[ 0  1  2  3  4]\n",
      "  [ 5  6  7  8  9]\n",
      "  [20 21 22 23 24]]\n",
      "\n",
      " [[10 11 12 13 14]\n",
      "  [15 16 17 18 19]\n",
      "  [25 26 27 28 29]]], shape=(2, 3, 5), dtype=int64)\n",
      "xz (axis=-1):\n",
      "tf.Tensor(\n",
      "[[[ 0  1  2  3  4 20 21 22 23 24]\n",
      "  [ 5  6  7  8  9 25 26 27 28 29]]\n",
      "\n",
      " [[10 11 12 13 14 30 31 32 33 34]\n",
      "  [15 16 17 18 19 35 36 37 38 39]]], shape=(2, 2, 10), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "x = np.arange(20).reshape(2, 2, 5)\n",
    "y = np.arange(20, 30).reshape(2, 1, 5)\n",
    "z = np.arange(20, 40).reshape(2, 2, 5)\n",
    "\n",
    "print(f\"x : {x.shape} \\n{x}\")\n",
    "print(f\"y : {y.shape} \\n{y}\")\n",
    "print(f\"z : {z.shape} \\n{z}\")\n",
    "\n",
    "xy = layers.Concatenate(axis=1)([x, y])\n",
    "print(f\"xy (axis=1):\")\n",
    "print(xy)\n",
    "\n",
    "xz = layers.Concatenate(axis=-1)([x, z])\n",
    "print(f\"xz (axis=-1):\")\n",
    "print(xz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "text (InputLayer)               [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "question (InputLayer)           [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, None, 10000)  640000      text[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 10000)  320000      question[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 32)           1284224     embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 16)           641088      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 48)           0           lstm[0][0]                       \n",
      "                                                                 lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 500)          24500       concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 2,909,812\n",
      "Trainable params: 2,909,812\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 1000\n",
    "max_length = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text.shape: (1000, 100)\n",
      "question.shape: (1000, 100)\n",
      "answers.shape: (1000,)\n",
      "answers.shape: (1000, 500)\n"
     ]
    }
   ],
   "source": [
    "text = np.random.randint(1, text_vocabulary_size, size=(num_samples, max_length))\n",
    "question = np.random.randint(1, question_vocabulary_size, size=(num_samples, max_length))\n",
    "answers = np.random.randint(0, answer_vocabulary_size, size=num_samples)\n",
    "print(f\"text.shape: {text.shape}\")\n",
    "print(f\"question.shape: {question.shape}\")\n",
    "print(f\"answers.shape: {answers.shape}\")\n",
    "\n",
    "answers = to_categorical(answers)\n",
    "print(f\"answers.shape: {answers.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit([text, question], answers, epochs=10, batch_size=128)\n",
    "# model.fit({'text': text, 'question': question}, answers, epochs=10, batch_size=128)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('tf26')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1e329751ad3fbc78699a5e88abe00d39aafe605dca43acf9894240e004a03697"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
